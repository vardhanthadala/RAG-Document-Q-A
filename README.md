# ğŸ“š RAG Document Q&A with Groq + Llama3 + HuggingFace Embeddings

This is a **Retrieval-Augmented Generation (RAG) app** built with:
- [Streamlit](https://streamlit.io/) â†’ Web UI  
- [LangChain](https://www.langchain.com/) â†’ Document loading, splitting, retrieval  
- [FAISS](https://github.com/facebookresearch/faiss) â†’ Vector database  
- [HuggingFace](https://huggingface.co/) â†’ Sentence embeddings  
- [Groq](https://groq.com/) â†’ Llama3 inference  

You can **ask questions** about your PDFs, and the app will retrieve relevant chunks and answer using Groqâ€™s Llama3 model.

---

## âš™ï¸ Setup

### 1. Clone & Install
```bash
git clone https://github.com/yourusername/rag-groq-hf.git
cd rag-groq-hf
python -m venv venv
venv\Scripts\activate    # On Windows
# or: source venv/bin/activate  (Linux/Mac)
pip install -r requirements.txt
