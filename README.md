# ğŸ“š RAG Document Q&A with Groq + Llama3 + HuggingFace Embeddings

This project is a **Retrieval-Augmented Generation (RAG) app** where you can ask questions about your PDFs.  
It uses:
- [Streamlit](https://streamlit.io/) â†’ Web UI  
- [LangChain](https://www.langchain.com/) â†’ Document loading, splitting, retrieval  
- [FAISS](https://github.com/facebookresearch/faiss) â†’ Vector database  
- [HuggingFace](https://huggingface.co/) â†’ Embeddings (`all-MiniLM-L6-v2`)  
- [Groq](https://groq.com/) â†’ Llama3 inference  

---

## âš™ï¸ Setup

### 1. Clone & Create Environment
```bash
git clone https://github.com/yourusername/rag-groq-hf.git
cd rag-groq-hf

# Create virtual environment
python -m venv venv
venv\Scripts\activate     # On Windows
# or
source venv/bin/activate  # On Linux/Mac

